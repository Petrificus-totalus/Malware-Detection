import json
from sklearn import model_selection
from sqlalchemy import cast, func, asc, desc
from sqlalchemy.types import DATE, TIME

from flask import current_app, request, jsonify, make_response, session
import hashlib
import os
import uuid

from werkzeug.utils import secure_filename
import numpy as np
import pandas as pd
from malware.models import User, UserFile, File, Sections, Ole, Comctl, Iphlpapi, Shell, Gdi, Ws, Kernel, Snmpapi, DllCha, Ch, Usersaner, Msvcrt
from malware import db
from flask_wtf import csrf
from . import api
from . import pefile
from . import utils

import time
import datetime


Alist = []

Alist_cs = []
f = pd.read_json('2000.json')
f = f[f['label'] != -1]
Adict = {}
for pe in f["imports"]:
    for key, values in pe.items():

        for value in values:
            if(value not in Adict):
                if "@"in value:
                    continue
                if "ord" in value.lower():
                    continue
                Adict[value] = len(Adict)
Alists = []


for pe in f["imports"]:
    Alist = [0] * len(Adict)
    for key, values in pe.items():
        for value in values:
            if "@"in value or "ord" in value.lower():
                continue

            ind = Adict[value]
            Alist[ind] = 1
    Alists.append(Alist)
X = np.array(Alists)
y = np.array(f.label)
X_train, X_test, y_train, y_test = model_selection.train_test_split(
    X, y, test_size=0.3, random_state=1)


# 判断文件夹是否存在，如果不存在则创建
if not os.path.exists('upload'):
    os.makedirs('upload')
else:
    pass


@api.route('/csrf')
def csrfToken():
    csrf_token = csrf.generate_csrf()  # 创建csrf_token 值
    resp = make_response()
    resp.set_cookie("csrf_token", csrf_token)  # 设置 cookie 值
    return resp


def decisionTree(file_data):
    filename = 'file_data.json'
    with open(filename, 'w') as f_obj:
        json.dump(file_data, f_obj)
    cs = pd.read_json('file_data.json')

    Adict_cs = {}
    for pe in cs["imports"]:
        for key, values in pe.items():
            for value in values:
                if(value not in Adict_cs):
                    if "@"in value:
                        continue
                    if "ord" in value.lower():
                        continue
                    Adict_cs[value] = len(Adict_cs)
    Alists_cs = []

    for pe in cs["imports"]:
        Alist_cs = [0] * len(Adict)
        # Alist_cs = [0] * 10486
        for key, values in pe.items():
            for value in values:
                if "@"in value or "ord" in value.lower():
                    continue

                ind = Adict_cs[value]
                Alist_cs[ind] = 1
        Alists_cs.append(Alist_cs)

    X_cs = np.array(Alists_cs)
    from sklearn.tree import DecisionTreeClassifier
    model = DecisionTreeClassifier(min_samples_leaf=10, random_state=1)
    model.fit(X_train, y_train)

    pred = model.predict(X_cs)
    # os.remove('file_data.json')
    return pred[0]


def addFile(data_source, status, user, filename, filesize):
    subsystem = data_source["header"]["optional"]["subsystem"]
    magic = data_source["header"]["optional"]["magic"]
    ma_i_v = data_source["header"]["optional"]["major_image_version"]
    mi_i_v = data_source["header"]["optional"]["minor_image_version"]
    ma_l_v = data_source["header"]["optional"]["major_linker_version"]
    mi_l_v = data_source["header"]["optional"]["minor_linker_version"]
    ma_os_v = data_source["header"]["optional"]["major_operating_system_version"]
    mi_os_v = data_source["header"]["optional"]["minor_operating_system_version"]
    ma_s_v = data_source["header"]["optional"]["major_subsystem_version"]
    mi_s_v = data_source["header"]["optional"]["minor_subsystem_version"]
    sizeof_c = data_source["header"]["optional"]["sizeof_code"]
    sizeof_h = data_source["header"]["optional"]["sizeof_headers"]
    sizeof_hc = data_source["header"]["optional"]["sizeof_heap_commit"]

    dllchas = data_source["header"]["optional"]["dll_characteristics"]
    dllcha = []
    for a in dllchas:
        dllcha.append(DllCha(name=a))

    timestamp = data_source["header"]["coff"]["timestamp"]
    machine = data_source["header"]["coff"]["machine"]

    chs = data_source["header"]["coff"]["characteristics"]
    ch = []
    for b in chs:
        ch.append(Ch(name=b))

    imports = data_source["imports"]

    keys = imports.keys()
    kernel = []
    user32 = []
    msvcrt = []
    snmpapi = []
    wS2_32 = []
    iphlpapi = []
    gDI32 = []
    shell32 = []
    comctl32 = []
    ole32 = []
    kernels = []
    if "KERNEL32.dll" in keys:
        kernels = imports["KERNEL32.dll"]

    elif "kernel32.dll" in keys:

        kernels = imports["kernel32.dll"]
    for c in kernels:
        kernel.append(Kernel(name=c))

    shell32s = []
    if "SHELL32.dll" in keys:
        shell32s = imports["SHELL32.dll"]
    elif "shell32.dll" in keys:
        shell32s = imports["shell32.dll"]

    for k in shell32s:
        shell32.append(Shell(name=k))

    user32s = []
    if "USER32.dll" in keys:
        user32s = imports["USER32.dll"]
    elif "user32.dll" in keys:
        user32s = imports["user32.dll"]
    for d in user32s:
        user32.append(Usersaner(name=d))
    msvcrts = []
    if "msvcrt.dll" in keys:
        msvcrts = imports["msvcrt.dll"]
    elif "MSVCRT.dll" in keys:
        msvcrts = imports["MSVCRT.dll"]
    for e in msvcrts:
        msvcrt.append(Msvcrt(name=e))
    ole32s = []
    if "ole32.dll" in keys:
        ole32s = imports["ole32.dll"]
    elif "OLE32.DLL" in keys:
        ole32s = imports["OLE32.DLL"]
    for m in ole32s:
        ole32.append(Ole(name=m))

    snmpapis = []
    if "snmpapi.dll" in keys:
        snmpapis = imports["snmpapi.dll"]
    for f in snmpapis:
        snmpapi.append(Snmpapi(name=f))

    wS2_32s = []
    if "WS2_32.dll" in keys:
        wS2_32s = imports["WS2_32.dll"]
    elif "ws2_32.dll" in keys:
        wS2_32s = imports["ws2_32.dll"]
    for g in wS2_32s:
        wS2_32.append(Ws(name=g))

    comctl32s = []
    if "COMCTL32.dll" in keys:
        comctl32s = imports["COMCTL32.dll"]
    elif "comctl32.dll" in keys:
        comctl32s = imports["comctl32.dll"]
    for l in comctl32s:
        comctl32.append(Comctl(name=l))

    gDI32s = []
    if "GDI32.dll" in keys:
        gDI32s = imports["GDI32.dll"]
    elif "gdi32.dll" in keys:
        gDI32s = imports["gdi32.dll"]
    for j in gDI32s:
        gDI32.append(Gdi(name=j))

    iphlpapis = []
    if "iphlpapi.dll" in keys:
        iphlpapis = imports["iphlpapi.dll"]
    for h in iphlpapis:
        iphlpapi.append(Iphlpapi(name=h))

    section = data_source["section"]["sections"]
    sections = []
    for i in section:
        sections.append(
            Sections(name=i["name"], size=i["size"], vsize=i["vsize"]))

    newf = File(md5=data_source["md5"], status=status, user=user, filename=filename, filesize=filesize, count=1, subsystem=subsystem, magic=magic, ma_i_v=ma_i_v, mi_i_v=mi_i_v, ma_l_v=ma_l_v, mi_l_v=mi_l_v, ma_os_v=ma_os_v, mi_os_v=mi_os_v, ma_s_v=ma_s_v, mi_s_v=mi_s_v, sizeof_c=sizeof_c,
                sizeof_h=sizeof_h, sizeof_hc=sizeof_hc, dllcha=dllcha, timestamp=timestamp, machine=machine, ch=ch, kernel=kernel, user32=user32, msvcrt=msvcrt, snmpapi=snmpapi, wS2_32=wS2_32, iphlpapi=iphlpapi, sections=sections, shell32=shell32, gDI32=gDI32, comctl32=comctl32, ole32=ole32)
    db.session.add(newf)
    db.session.commit()

    return newf


@api.route('/upload', methods=["POST"])
def upload():
    data = request.files.get("file")
    # 注意：没有的文件夹一定要先创建，不然会提示没有该路径

    filename = data.filename.split(".")[0]

    path = os.path.join('upload', secure_filename(filename))
    data.save(path)
    filesize = os.path.getsize(path)  # Bytes

    pe = pefile.PE(path)
    pe_start = datetime.datetime.now()
    data_source = utils.handleEXE(pe)
    pe_end = datetime.datetime.now()
    pe_time = (pe_end - pe_start).total_seconds()

    hash_md5 = hashlib.md5()
    with open(path, mode='rb') as f:
        for line in f:
            hash_md5.update(line)
    md5 = hash_md5.hexdigest()

    data_source["md5"] = md5

    email = session.get("email")  # 获取当前用户
    f = File.query.filter_by(md5=md5).first()
    id = 0
    # DB 中没有这个文件
    if f is None:
        check_start = datetime.datetime.now()
        result = decisionTree([data_source])
        check_end = datetime.datetime.now()
        check_time = (check_end - check_start).total_seconds()

        status = "unsafe"
        if result == 0:
            status = "safe"

        # 未登陆
        if email is None:
            newf = addFile(data_source, status, "Unknown", filename, filesize)

            uid = str(uuid.uuid1())
            session["Unknown"] = uid
            user = User(username="Unknown", email=uid)
            user.pwd = "Unknown"
            user.files.append(newf)
            db.session.add(user)
            db.session.commit()

            userfile = UserFile.query.filter_by(
                email=uid, md5=md5, exist="null").first()

            userfile.count = 0
            userfile.pe_time = pe_time
            userfile.check_time = check_time
            userfile.uploadorsearch = "upload"
            id = userfile.id
            db.session.commit()

        # 登陆
        else:
            newf = addFile(data_source, status, email, filename, filesize)
            user = User.query.filter_by(email=email).first()
            user.files.append(newf)
            db.session.commit()
            userfile = UserFile.query.filter_by(
                email=email, md5=md5, exist="null").first()
            userfile.exist = "no"
            userfile.count = 0
            userfile.pe_time = pe_time
            userfile.check_time = check_time
            userfile.uploadorsearch = "upload"
            id = userfile.id

            db.session.commit()

    # DB 中有这个文件
    else:
        if email is not None:
            user = User.query.filter_by(email=email).first()
            count = f.count
            f.count += 1
            db.session.commit()
            newf = UserFile(email=email, md5=f.md5, count=count)
            db.session.add(newf)

            userfile = UserFile.query.filter_by(
                email=email, md5=f.md5, exist="null").first()
            userfile.exist = "yes"
            userfile.pe_time = pe_time
            userfile.check_time = -1
            userfile.uploadorsearch = "upload"
            id = userfile.id

            db.session.commit()
        else:
            uid = str(uuid.uuid1())
            session["Unknown"] = uid

            user = User(username="Unknown", email=uid)
            user.pwd = "Unknown"
            db.session.add(user)

            user.files.append(f)
            count = f.count

            f.count += 1

            userfile = UserFile.query.filter_by(
                email=uid, md5=f.md5, exist="null").first()
            userfile.exist = "yes"
            userfile.count = count
            userfile.pe_time = pe_time
            userfile.uploadorsearch = "upload"

            userfile.check_time = -1
            id = userfile.id

            db.session.commit()

    # 检测完删除 upload 中的 exe 文件
    if os.path.exists(path):
        os.remove(path)

    return jsonify({"md5": md5, "id": id})


@api.route('/searchfileid/<id>', methods=["GET"])
def searchfileid(id):
    userfile = UserFile.query.filter_by(
        id=id).first()
    f = File.query.filter_by(md5=userfile.md5).first()

    coff = receiveCoff(f)
    sections = receiveSections(f)
    optional = receiveOptionalHeader(f)
    imports = receiveImports(f)

    return jsonify({"imports": imports, "optional": optional, "sections": sections, "coff": coff, "md5": userfile.md5, "status": f.status, "filename": f.filename, "filesize": f.filesize, "user": f.user, "time": f.create_time, "currentcount": userfile.count, "count": f.count, "exist": userfile.exist, "pe_time": userfile.pe_time, "check_time": userfile.check_time, "uploadorsearch": userfile.uploadorsearch})


def receiveSections(f):
    sections = []
    for b in f.sections:
        sections.append({"name": b.name, "size": b.size, "vsize": b.vsize})
    return sections


def receiveCoff(f):
    characteristics = []
    for a in f.ch:
        characteristics.append(a.name)

    coff = {
        "timestamp": f.timestamp,
        "machine": f.machine,
        "characteristics": characteristics
    }
    return coff


def receiveOptionalHeader(f):
    dll_characteristics = []
    for a in f.dllcha:
        dll_characteristics.append(a.name)
    optional = {
        "subsystem": f.subsystem,
        "dll_characteristics": dll_characteristics,
        "magic": f.magic,
        "major_image_version": f.ma_i_v,
        "minor_image_version": f.mi_i_v,
        "major_linker_version": f.ma_l_v,
        "minor_linker_version": f.mi_l_v,
        "major_operating_system_version": f.ma_os_v,
        "minor_operating_system_version": f.mi_os_v,
        "major_subsystem_version": f.ma_s_v,
        "minor_subsystem_version": f.mi_s_v,
        "sizeof_code": f.sizeof_c,
        "sizeof_headers": f.sizeof_h,
        "sizeof_heap_commit": f.sizeof_hc
    }
    return optional


def receiveImports(f):
    kernel = []
    user32 = []
    msvcrt = []
    snmpapi = []
    wS2_32 = []
    gDI32 = []
    iphlpapi = []
    shell32 = []
    comctl32 = []
    ole32 = []

    for a in f.kernel:
        kernel.append(a.name)
    for a in f.user32:
        user32.append(a.name)
    for a in f.msvcrt:
        msvcrt.append(a.name)
    for a in f.snmpapi:
        snmpapi.append(a.name)
    for a in f.wS2_32:
        wS2_32.append(a.name)
    for a in f.gDI32:
        gDI32.append(a.name)
    for a in f.iphlpapi:
        iphlpapi.append(a.name)
    for a in f.shell32:
        shell32.append(a.name)
    for a in f.comctl32:
        comctl32.append(a.name)
    for a in f.ole32:
        ole32.append(a.name)

    imports = [
        {"name": "kernel", "data": kernel},
        {"name": "user32", "data": user32},
        {"name": "msvcrt", "data": msvcrt},
        {"name": "snmpapi", "data": snmpapi},
        {"name": "wS2_32", "data": wS2_32},
        {"name": "gDI32", "data": gDI32},
        {"name": "iphlpapi", "data": iphlpapi},
        {"name": "shell32", "data": shell32},
        {"name": "comctl32", "data": comctl32},
        {"name": "ole32", "data": ole32},
    ]

    return imports


@api.route('/searchfilemd5/<md5>', methods=["GET"])
def searchfilemd5(md5):
    email = session.get("email")  # 获取当前用户
    if email is None:
        email = str(uuid.uuid1())
        user = User(username="Unknown", email=email)
        user.pwd = "Unknown"
        db.session.add(user)
        db.session.commit()

    f = File.query.filter_by(md5=md5).first()
    count = f.count
    f.count += 1
    db.session.commit()
    newf = UserFile(email=email, md5=f.md5, count=count,
                    uploadorsearch="搜索", exist="yes", pe_time=-1, check_time=-1)
    db.session.add(newf)
    db.session.commit()
    coff = receiveCoff(f)
    sections = receiveSections(f)
    optional = receiveOptionalHeader(f)
    imports = receiveImports(f)

    return jsonify({"imports": imports, "optional": optional, "sections": sections, "coff": coff, "md5": md5, "status": f.status, "filename": f.filename, "filesize": f.filesize, "user": f.user, "time": f.create_time, "count": f.count})

# search.vue
@api.route('/searchall', methods=["GET"])
def searchall():
    f = File.query.filter_by().order_by(File.count.desc()).limit(36).all()
    files = []
    for a in f:
        files.append({
            "md5": a.md5,
            "filename": a.filename,
            "status": a.status,
            "time": a.create_time,
            "user": a.user,
            "count": a.count,
            "filesize": a.filesize
        })
    return jsonify({"result": files})


@api.route('/historySearch', methods=["POST"])
def historySearch():

    email = request.form.get("email")
    page = request.form.get("page")
    userfile = UserFile.query.filter_by(
        email=email).all()

    count = request.form.get("count")
    time = request.form.get("time")
    date1 = request.form.get("date1")
    date2 = request.form.get("date2")

    arg = {}
    keys = request.form.keys()
    for a in conditions:
        value = request.form.get(a)
        if value != '':
            arg[a] = value.strip()

    ffs = File.query.filter_by(**arg).all()

    filelist = []
    for a in userfile:
        ts = a.create_time.timestamp() * 1000
        if int(ts) >= int(date1) and ts <= int(date2):
            filelist.append(a)

    userfile = filelist
    fs = []
    for i in userfile:
        for j in ffs:
            if j.md5 == i.md5:
                fs.append(i)

    if count == "countDesc":
        if time == "timeDesc":
            fs.sort(key=sortRule_dd)
        else:
            fs.sort(key=sortRule_da)
    else:
        if time == "timeDesc":
            fs.sort(key=sortRule_ad)
        else:
            fs.sort(key=sortRule_aa)
    # user = User.query.filter_by(email=email).first()
    total = len(fs)

    end = 4*int(page)
    start = end-4
    if end > total:
        end = total
    fileList = []
    fs = fs[start:end]
    for f in fs:
        ff = File.query.filter_by(md5=f.md5).first()

        fileList.append({"id": f.id, "md5": f.md5, "filename": ff.filename, "filesize": ff.filesize, "status": ff.status,
                         "time": f.update_time, "user": ff.user, "count": f.count, "allcount": ff.count})
    return jsonify({"fileList": fileList, "total": total})


@api.route('/dele', methods=["POST"])
def dele():
    deleteList = request.form.get("deleteList")
    dl = deleteList.split(",")
    for id in dl:
        UserFile.query.filter_by(
            id=int(id)).delete()

    db.session.commit()
    return jsonify({"code": "ok"})


@api.route('/deleall', methods=["GET"])
def deleall():
    email = session.get("email")  # 获取当前用户
    user = User.query.filter_by(email=email).first()
    UserFile.query.filter_by(
        email=email).delete()

    db.session.commit()
    return jsonify({"code": "ok"})


def sortRule_dd(ele):
    count = ele.count
    ts = int(ele.create_time.timestamp())
    return -count, -ts


def sortRule_da(ele):
    count = ele.count
    ts = int(ele.create_time.timestamp())
    return -count, ts


def sortRule_ad(ele):
    count = ele.count
    ts = int(ele.create_time.timestamp())
    return count, -ts


def sortRule_aa(ele):
    count = ele.count
    ts = int(ele.create_time.timestamp())
    return count, ts


conditions = ["status", "filename", "md5"]


@api.route('/search', methods=["POST"])
def search():
    status = request.form.get("status")
    count = request.form.get("count")
    page = request.form.get("page")
    time = request.form.get("time")
    date1 = request.form.get("date1")
    date2 = request.form.get("date2")

    arg = {}
    keys = request.form.keys()
    for a in conditions:
        value = request.form.get(a)
        if value != '':
            arg[a] = value.strip()

    fs = File.query.filter_by(**arg).all()
    fileList = []
    for a in fs:
        ts = a.create_time.timestamp() * 1000
        if int(ts) >= int(date1) and ts <= int(date2):
            fileList.append(a)

    fs = fileList

    if count == "countDesc":
        if time == "timeDesc":
            fs.sort(key=sortRule_dd)
        else:
            fs.sort(key=sortRule_da)
    else:
        if time == "timeDesc":
            fs.sort(key=sortRule_ad)
        else:
            fs.sort(key=sortRule_aa)

    total = len(fs)

    end = 16*int(page)
    start = end-16
    if end > total:
        end = total
    fileList = []
    files = fs[start:end]
    for a in files:

        fileList.append({
            "md5": a.md5,
            "filename": a.filename,
            "status": a.status,
            "time": a.create_time,
            "user": a.user,
            "count": a.count,
            "filesize": a.filesize})
    return jsonify({"fileList": fileList, "total": total})
